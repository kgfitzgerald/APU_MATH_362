---
title: "Week 05 Day 02"
subtitle: ""
output: 
  html_document:
    toc: true
    toc_float: true
    number_section: false
    highlight: tango
    theme: "cosmo"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE)
```

# Student Questions

+ What does $\Phi$ stand for? How do we enter $\Phi$ in RStudio?

+ How do we calculate the power if we don't know $\mu$?

+ Will we ever work backwards where we don't determine $\alpha$ ahead of time?
    + Four unknowns: [Power app](https://rpsychologist.com/d3/nhst/)
    
+ Why are we only aiming for 80% power/20% Type II error?

+ Why is 215 more "scientifically meaningful" than 201? 
    + $H_0: \mu = 200$ (mean blood cholesterol in mg/dl)
    
+ How do we define the boundary of whether or not it is "scientifically meaningful"? It all seems very subjective. 

+ Why would we calculate power for multiple $\mu$ values?

+ Are there easy ways of calculating power using R?

+ This reminds me of what we demonstrated in class last week; that if n is large enough I can technically force my standard error to be small enough so as to reject the null hypothesis even when the alternative is not that much different from it. I think this idea of statistical vs practical significance is really important especially when it comes to applications in, say, medicine or science. I do wonder what some of the trade offs would be though. Like, at what point can we say that the sample size is too big?




# Knowledge Check

1. What symbols do we use to represent Type I and Type II error?

2. Describe as best you can what's going on in the picture below

```{r}
knitr::include_graphics("./images/power-sketch-psu.png")
```

3. If $\beta = 0.2$ for a given hypothesis test, what is the power of the test?

4. When designing a study, what are two main goals regarding Type I error and power?

5. Consider a hypothesis $H_0: \mu = 400$ vs $H_A: \mu > 400$. Will the power of this test be higher when the true parameter value is 437 or 407? Why? Draw a picture to illustrate. 

6. What happens to the power of a test as the true parameter moves farther away from the parameter hypothesized under the null hypothesis? 

7. Describe as best you can what's going on in the picture below. What happens to the power of a test if you change the $\alpha$ value? What does this tell you about the relationship between Type I and Type II error? 

```{r}
knitr::include_graphics("./images/power-sketch-change-alpha.png")
```

8. What happens to the power of a test as the sample size increases?
