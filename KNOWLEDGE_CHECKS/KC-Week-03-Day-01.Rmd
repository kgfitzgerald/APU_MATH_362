---
title: "Week 03 Day 01"
subtitle: ""
output: 
  html_document:
    toc: true
    toc_float: true
    number_section: false
    highlight: tango
    theme: "cosmo"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE)
```

## Knowledge Check

For Questions 1-5, use the following scenario. Let $X_1, X_2, \dots X_n \sim N(\mu_X, \sigma^2)$ and $Y_1, Y_2, \dots Y_n \sim N(\mu_Y, \sigma^2)$ be independent random samples.

1. How is $\overline{X} - \overline{Y}$ distributed?
1. How is $\frac{(\overline{X} - \overline{Y}) - (\mu_X - \mu_Y)}{\sqrt{\frac{\sigma^2}{n} + \frac{\sigma^2}{m}}}$ distributed?
1. How are $\frac{(n-1)S_x^2}{\sigma^2}$  and $\frac{(m-1)S_y^2}{\sigma^2}$ distributed?
1. How is $\frac{(n-1)S_x^2}{\sigma^2} + \frac{(m-1)S_y^2}{\sigma^2}$ distributed?
1. If $Z \sim N(0,1)$ and $U \sim \chi^2_{df}$, how is $\frac{Z}{\sqrt{U/df}}$ distributed? 

1. When should you use Welch's t-interval? 
1. When should you use a paired t-interval?

## Questions

+ When do we use t vs z?!?!?!?!?! :)

    + Simplified answer: t for means, z for proportions
    + Butttttt, for sample size calculations, we have to settle for z, even for means
    
+ Statistical thinking pro-tip: think in terms of best/worst case scenarios, upper/lower bounds. Can get you a long way towards a practical decision! 

    + "How much would my results change if I'm wrong about XYZ?" Robustness checks.
    + Just because a value is technically unknown, doesn't mean we don't know ANYTHING about that value. Even rough estimates help gain traction on a problem. Think: orders of magnitude. 

+ *"[Paired t-test] would only work if sample sizes m and n are equal correct? Or else some of the observations would be left unpaired? But I can't help but wonder: if this was like a before and after study of the same subjects, but for whatever reason, data was not obtained "afterwards" for some of the subjects, what do we do then? Do we just ignore those observations and use this method, limiting our sample size only to those we have data for before and after?"*

+ Should we always assume random data is independent?

<!-- 1. What  formula do you use to compute the sample size needed for estimating $\mu$?  -->

<!-- 1. What is the hardest part about using the above formula? Why?  -->

<!-- 1. Comment on what each symbol in the formula in #1 means and how you obtain values to plug in. -->

<!-- 1. When estimating a mean, will increasing your level of confidence require more or less necessary sample size? Why?  -->

<!-- 1. When estimating a mean, does a random variable with a larger variance require more or less necessary sample size? Why?  -->

<!-- 1. When estimating a mean, will increasing your margin of error require more or less necessary sample size? Why?  -->

<!-- 1. What  formula do you use to compute the sample size needed for estimating $p$?  -->

<!-- 1. What is the hardest part about using the above formula? Why?  -->

<!-- 1. Comment on what each symbol in the formula in #7 means and how you obtain values to plug in. -->

<!-- 1. Comment on how and why the formulas in #1 and #7 relate to one another. -->

<!-- 1. When estimating $p$, what happens to the necessary sample size as $\hat{p}$ changes? -->